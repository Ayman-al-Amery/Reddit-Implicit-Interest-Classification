{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da17a2b",
   "metadata": {},
   "source": [
    "# GA DSI 21 - Capstone Project \n",
    "## Ayman al Amery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ec63c",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "Can we predict whether a reddit user has interacted / will interact with a particular subreddit (e.g. wallstreetbets) based on their previous interactions with other subreddits?\n",
    "\n",
    "Where an interaction with a subreddit is defined as publishing a post or comment in that subreddit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49699c",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "- Used OAUTH Web Token to access Reddit API from which data was sourced\n",
    "- Definined several seed subreddits from which I collected the authors of the 100 most recent posts\n",
    "- Then collected the authors of the comments on each of the 100 most recent posts\n",
    "\n",
    "\n",
    "- For each author, I accessed the metadata of each of their 100 most recent posts and 100 most recent comments\n",
    "- From the metadata I collected the subreddit, score, number of awards & number of comments for each post/comment (Note: comment metadata contains no information regarding number of comments/replies made on author's comment so filled with NaN)\n",
    "- Reddit does not provide data regarding which subreddits a user is subscribed to, as such this alternative was used to serve as proxy\n",
    "\n",
    "\n",
    "- For each given user I aggregated the data by subreddit calculating the number of interactions by the user with that particular subreddit and mean of each of the other features mentioned above\n",
    "- Then for each subreddit interacted with by the given user, I used the various attributes to create a single value for that subreddit and user pair\n",
    "- Finally I transformed the results into a single row of a DataFrame for each user\n",
    "\n",
    "\n",
    "- Something about EDA\n",
    "- Removing outliers\n",
    "- Something about Feature Selection\n",
    "\n",
    "\n",
    "- Something about Modelling and Analysis/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab9b44",
   "metadata": {},
   "source": [
    "# Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8836ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import requests\n",
    "import requests.auth\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c683b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials\n",
    "\n",
    "clientid = '*****'\n",
    "secret = '*****'\n",
    "app_name = '*****'\n",
    "\n",
    "username = '*****'\n",
    "password = '*****'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a1d06a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61805754-br2x43JsLFQuYL1fKa-piAOoDbrtrA'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting Web Token to access Reddit API\n",
    "\n",
    "client_auth = requests.auth.HTTPBasicAuth(f'{clientid}', f'{secret}')\n",
    "post_data = {\"grant_type\": \"password\", \"username\": f\"{username}\", \"password\": f\"{password}\"}\n",
    "headers = {\"User-Agent\": f\"script:com.example.{app_name}:v1.0.0 (by u/{username})\"}\n",
    "response = requests.post(\"https://www.reddit.com/api/v1/access_token\", auth=client_auth, data=post_data, headers=headers)\n",
    "token = response.json()['access_token']\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4504cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'wallstreetbets', 'aww', 'food', 'science'\n",
    "\n",
    "seed_subreddit = 'science'\n",
    "\n",
    "users = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f34b269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the authors and URLs of the 100 most recent posts in the seed subreddit\n",
    "\n",
    "links = []\n",
    "\n",
    "headers = {\"Authorization\": f\"bearer {token}\", \"User-Agent\": f\"script:com.example.{app_name}:v1.0.0 (by u/{username})\"}\n",
    "response = requests.get(f\"https://oauth.reddit.com/r/{seed_subreddit}?limit=100\", headers=headers)\n",
    "\n",
    "\n",
    "for i in range(len(response.json()['data']['children'])):\n",
    "    \n",
    "    author = response.json()['data']['children'][i]['data']['author']\n",
    "    link = response.json()['data']['children'][i]['data']['permalink']\n",
    "    \n",
    "    users.append(author)\n",
    "    links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162a885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the authors of comments on each of the 100 most recent posts \n",
    "\n",
    "for post in links:\n",
    "    \n",
    "    headers = {\"Authorization\": f\"bearer {token}\", \"User-Agent\": f\"script:com.example.{app_name}:v1.0.0 (by u/{username})\"}\n",
    "    response = requests.get(f\"https://oauth.reddit.com{post}?limit=1000\", headers=headers)\n",
    "    \n",
    "    for i in range(len(response.json()[1]['data']['children'])):\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            author = response.json()[1]['data']['children'][i]['data']['author']\n",
    "        \n",
    "            users.append(author)\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a4c2dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1302, 959)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying number of unique users\n",
    "\n",
    "len(users), len(set(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5b2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving unique users to CSV\n",
    "\n",
    "unique_users = list(set(users))\n",
    "users = pd.DataFrame(unique_users, columns=['user'])\n",
    "users.to_csv(f'{seed_subreddit}_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07e7e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an empty dictionary \n",
    "\n",
    "subreddits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eea385a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmokeyBare\n",
      "machine_yearning\n",
      "LetReasonRing\n",
      "TomorrowWeKillToday\n",
      "Rupertfitz\n",
      "flyunderradar\n",
      "Zupheal\n",
      "LoverOfPricklyPear\n",
      "hubertortiz\n",
      "grey_seal77\n",
      "icecreamlava\n",
      "paulfromatlanta\n",
      "nothaut\n",
      "woNubvJjg5KtwoHAOg1A\n",
      "WildGooseCarolinian\n",
      "bitskewer\n",
      "IOnlySayMeanThings\n",
      "MisterEChops\n",
      "cockroachjuice\n",
      "unabashedboy\n",
      "differentiatedpans\n",
      "Luffy507\n",
      "Lord_Augastus\n",
      "Not_Legal_Advice_Pod\n",
      "MissionComfortable47\n",
      "NicNoletree\n",
      "Exastiken\n",
      "Callec254\n",
      "DrunkenSealPup\n",
      "PistisDeKrisis\n",
      "megalink5713\n",
      "Gallionella\n",
      "ImAlsoAHooman\n",
      "Bubotuberpuss\n",
      "getupkitten\n",
      "cbbuntz\n",
      "Mythril_Bahaumut\n",
      "Fun-Dragonfruit2999\n",
      "kingofwale\n",
      "rustoo\n",
      "Darth_Kahuna\n",
      "Hieb\n",
      "systemprocessing\n",
      "ExtraArrogantBastard\n",
      "mcninja77\n",
      "PhD_Pwnology\n",
      "ConcussionsOfAParot\n",
      "shartymcqueef\n",
      "kink-dinka-link\n",
      "KillerJupe\n",
      "JTiB\n",
      "fusiformgyrus\n",
      "jaguarthrone\n",
      "LiCHtsLiCH\n",
      "Rowdycc\n",
      "Azahk101\n",
      "SteinersGrave\n",
      "vivaramones\n",
      "DeadPoster\n",
      "MilkofGuthix\n",
      "rbalduf1818\n",
      "devnull791101\n",
      "Nervous-Violinist-32\n",
      "ThePathToOne\n",
      "FartandSminal\n",
      "DreddPirateJonesy\n",
      "pencile5\n",
      "YetAnotherEden\n",
      "AmiInderSchweiz\n",
      "SpyTheRedEye\n",
      "Slapppyface\n",
      "NightlyWry\n",
      "MacduffFifesNo1Thane\n",
      "Major_R_Soul\n",
      "nubsauce87\n",
      "LuisLmao\n",
      "TheBaconDeeler\n",
      "Dry-Kangaroo-8542\n",
      "chrisdh79\n",
      "Exact_Quote_6132\n",
      "ifoundit1\n",
      "pbro9\n",
      "jokl66\n",
      "lakeeriedude\n",
      "byraq\n",
      "FlyingFox86\n",
      "xiphoidthorax\n",
      "Rev0lutionDaddy\n",
      "RegressToTheMean\n",
      "fabjackiejab\n",
      "mubukugrappa\n",
      "_Badlands_\n",
      "accordingtotegan\n",
      "Melancholy43952\n",
      "Downtown-Panda-3395\n",
      "ducktor0\n",
      "PmMeIrises\n",
      "towcar\n",
      "shane727\n",
      "alexanderlot\n",
      "slantedangle\n",
      "MyKarma8MyDogma\n",
      "TsukiZombina\n",
      "Savioritis\n",
      "89ATM\n",
      "findingdumb\n",
      "Nussy5\n",
      "Purple_Passion000\n",
      "MasterbeaterPi\n",
      "giuliomagnifico\n",
      "somethingdangerzone\n",
      "Morisal66\n",
      "GeezUp777\n",
      "oscillius\n",
      "bpeden99\n",
      "Western_Entertainer7\n",
      "Mcozy333\n",
      "neodymium1337\n",
      "Applepi_Matt\n",
      "iim7_V6_IM7_vim7\n",
      "rebri\n",
      "Moot_Points\n",
      "rjbarns\n",
      "lastmindisaster\n",
      "jasonsawtelle\n",
      "Reaver_XIX\n",
      "machaca_master\n",
      "Cryptoscope8\n",
      "NevyTheChemist\n",
      "Anthill8\n",
      "MobyVic\n",
      "spiritualien\n",
      "imustbetaylor\n",
      "FredBob5\n",
      "Doser91\n",
      "BirdEducational6226\n",
      "robotbootyhunter\n",
      "SlySlickWicked\n",
      "Dermutt100\n",
      "GrungeHamster23\n",
      "T-Flexercise\n",
      "Grinagh\n",
      "Modavo\n",
      "HistoricalSubject\n",
      "BarnYardFiddler\n",
      "gattapenny\n",
      "impactwilson\n",
      "cjc323\n",
      "BeepBleepBoop\n",
      "Nauin\n",
      "Lucky210\n",
      "Dexdiman\n",
      "secnull\n",
      "apisarenco\n",
      "wh4tth3huh\n",
      "Jesuslordofporn\n",
      "VanillaGorilla40\n",
      "mcstafford\n",
      "Boggereatinarkie\n",
      "LizardWizardx\n",
      "orpheus497\n",
      "EricForce\n",
      "Durpdurpforyou\n",
      "SWWayin\n",
      "GenericOfficeMan\n",
      "hammyFbaby\n",
      "benjacob30\n",
      "jetro30087\n",
      "mustainsally\n",
      "shawnwingsit\n",
      "C4-BlueCat\n",
      "Cdesese\n",
      "kittenTakeover\n",
      "oO0-__-0Oo\n",
      "TakeDownYourLights\n",
      "DeneHero\n",
      "Eirikur_da_Czech\n",
      "BisonRancher\n",
      "Strangeboganman\n",
      "penguinchem13\n",
      "EvilRado\n",
      "ParabellumJohn\n",
      "Ms-Panumbra\n",
      "flaagan\n",
      "dirtymoney\n",
      "IntelligentLaugh4530\n",
      "Roseybelle\n",
      "AplastandoCalabazas\n",
      "xvart\n",
      "skeptical_mother\n",
      "WitNick\n",
      "AthKaElGal\n",
      "SweatingSeltzerGirl\n",
      "ebolaRETURNS\n",
      "outerworldLV\n",
      "Red-Freckle\n",
      "scorpionandrose\n",
      "thegeekwholived\n",
      "Ongo_Gablogian716\n",
      "Belgeirn\n",
      "dabartisLr\n",
      "2Throwscrewsatit\n",
      "terrytoy\n",
      "tewnewt\n",
      "santichrist\n",
      "osdre\n",
      "Mkwdr\n",
      "CreativeInstinks\n",
      "xplar\n",
      "Olorin_in_the_West\n",
      "autumn_rains\n",
      "Herazim\n",
      "Practical-Noobie\n",
      "Redditsoldestaccount\n",
      "_cafe_bustelo_\n",
      "Masterblaster13f\n",
      "hobovalentine\n",
      "nick351\n",
      "lost_in_life_34\n",
      "McRazzles\n",
      "nikan69\n",
      "occupying_space\n",
      "asterik216\n",
      "LemursRideBigWheels\n",
      "SeanyDay\n",
      "WittedGnat\n",
      "CuteNCaffeinated\n",
      "jwill602\n",
      "Lebenslust\n",
      "ParkieDude\n",
      "Compy222\n",
      "RegencyAndCo\n",
      "NightHalcyon\n",
      "_DeanRiding\n",
      "RaiderMan1\n",
      "Cosmonate\n",
      "Kayseejae\n",
      "orcinus__orca\n",
      "felonius_monk27\n",
      "thelovelyrose99\n",
      "Zeno_the_Friend\n",
      "Anonysmouse\n",
      "2Big_Patriot\n",
      "BrexitBlaze\n",
      "[deleted]\n",
      "------ No Posts ------\n",
      "------ No Comments ------\n",
      "Wsemenske\n",
      "Reddit_Retarrd\n",
      "jlevy1126\n",
      "BlishBlash\n",
      "The_AnxiousFem\n",
      "Supertho\n",
      "KittensofDestruction\n",
      "Tiltedaxis111\n",
      "nicolenotnikki\n",
      "zdepthcharge\n",
      "JohnnyAK907\n",
      "blippityblop\n",
      "OldMuley\n",
      "Meanwhile-in-Paris\n",
      "Wrekkanize\n",
      "Hefty-Revenue5547\n",
      "Onlymediumsteak\n",
      "Shawarma_Chameleon\n",
      "BeowulfShaeffer\n",
      "Teal_Dreams_\n",
      "Nixplosion\n",
      "armrha\n",
      "EmbarrassedHelp\n",
      "CMG30\n",
      "red_constellations\n",
      "Xerenopd\n",
      "sakurashinken\n",
      "YouAreNotYouYoureMe\n",
      "mhaddog00k\n",
      "wheresmynightcheese\n",
      "LK09\n",
      "tkdyo\n",
      "Negative-Custard5612\n",
      "Doom_Eagles\n",
      "OwlBeneficial2743\n",
      "squigglyeyeline\n",
      "merlinsbeers\n",
      "Lautheris\n",
      "reb0014\n",
      "Ask-Reggie\n",
      "JOSimpson\n",
      "reptargodzilla2\n",
      "whitebelt4lyfe\n",
      "GeoGeoGeoGeo\n",
      "pencock\n",
      "LemmeLaroo\n",
      "gentleman-corpse\n",
      "camilo16\n",
      "KingGidorah\n",
      "colorsflush\n",
      "canoxen\n",
      "squirrelinthetree\n",
      "pole_fan\n",
      "MJWood\n",
      "x47126g\n",
      "Random-Mutant\n",
      "cyberentomology\n",
      "themegabuck\n",
      "roterolenimo\n",
      "Lingenfelter\n",
      "themangastand\n",
      "qualmton\n",
      "WossamottaU\n",
      "swiftessence\n",
      "rricenator\n",
      "hengamp\n",
      "camjam20xx\n",
      "Extension_Start947\n",
      "upboat_consortium\n",
      "NightMgr\n",
      "CosmicIdiot99\n",
      "inkseep1\n",
      "ManThatIsFucked\n",
      "-o_-o\n",
      "MetaDragon11\n",
      "augustusleonus\n",
      "BSB8728\n",
      "Phantasius224\n",
      "vbcbandr\n",
      "mcogneto\n",
      "thornyRabbt\n",
      "Human-ish514\n",
      "di1d0\n",
      "Arqus2\n",
      "mini-scars\n",
      "dlw1sc\n",
      "imapilotaz\n",
      "jcvzneuro\n",
      "debiwen\n",
      "koomahnah\n",
      "---TheFierceDeity---\n",
      "5Lastronaut\n",
      "clotpole02\n",
      "tremendousspeller\n",
      "Pretty-Schedule2394\n",
      "Coady_L\n",
      "mentel42\n",
      "SuspiciousStable9649\n",
      "littlejohnnyjewel\n",
      "lizardshapeshifter\n",
      "justpress2forawhile\n",
      "usefoolidiot\n",
      "dwellerofcubes\n",
      "erdie721\n",
      "DrMaxCoytus\n",
      "ShotBuilder6774\n",
      "GodricGryffindor87\n",
      "MrSnowden\n",
      "FatherMiyamoto\n",
      "i_shouldnt_live\n",
      "Haplo164\n",
      "Lachee\n",
      "McSkinz\n",
      "croolshooz\n",
      "QuarantineSucksALot\n",
      "KiwisEatingKiwis\n",
      "20erMcNuggets\n",
      "Elvensabre\n",
      "k3surfacer\n",
      "Able-Office7733\n",
      "lunasmydog\n",
      "kay_bizzle\n",
      "fluentinimagery\n",
      "bundt_chi\n",
      "SeasonPositive6771\n",
      "teabagalomaniac\n",
      "godsinunknown\n",
      "littleventus\n",
      "wernermuende\n",
      "greeenie7gh\n",
      "BellumSuprema\n",
      "Ian_Campbell\n",
      "fishspit\n",
      "murderrabbit\n",
      "Nirvanablue92\n",
      "PyroCatt\n",
      "shlnglls\n",
      "Sunzidane\n",
      "molrose96\n",
      "AkagamiBarto\n",
      "autismextrovert\n",
      "MyBunnyIsCuter\n",
      "savage_slurpie\n",
      "manlymann\n",
      "Thopterthallid\n",
      "Zaptruder\n",
      "Apple_remote\n",
      "Jenovas_Witless\n",
      "biological_assembly\n",
      "Whorable-Religion\n",
      "AcolyteOfCynicism\n",
      "Slurm818\n",
      "MikeSciGuy\n",
      "tommygunz007\n",
      "InertiaFusion\n",
      "Consistent_Cod844\n",
      "Spiritual-Chameleon\n",
      "Additional_Soft7526\n",
      "masonjam\n",
      "davidmlewisjr\n",
      "Dithyrab\n",
      "IAmPriya_\n",
      "Ayemann\n",
      "Leviathan3333\n",
      "HarryMcDowell\n",
      "GloriuContentYT2\n",
      "Muddycarpenter\n",
      "Imnogrinchard\n",
      "Pr0gr3s\n",
      "dwntownlove\n",
      "FillsYourNiche\n",
      "Artscientist\n",
      "Candid_Indication_45\n",
      "fuzzyshorts\n",
      "thisimpetus\n",
      "RonConComa\n",
      "Mortenbrownsound\n",
      "better-tomorrow2827\n",
      "Wild-Kitchen\n",
      "cast26\n",
      "-cochise\n",
      "xximcmxci\n",
      "pongaminbloom\n",
      "BottasHeimfe\n",
      "CoffeeBoom\n",
      "doubtmeow\n",
      "PC-hris\n",
      "GainzdalfTheWhey\n",
      "ProgenyOfEurope\n",
      "mr_asadshah\n",
      "CookiemonsterDK\n",
      "Sardonislamir\n",
      "luckytaurus\n",
      "Shmoode\n",
      "balanced_view\n",
      "hellscape_goat\n",
      "Valgor\n",
      "WaddlingHippos\n",
      "Petey_Pablo_\n",
      "Ghost_Gamer_918\n",
      "Blissful_Solitude\n",
      "Isabellaboo02\n",
      "Grut0l\n",
      "HeinieKaboobler\n",
      "LeEbinUpboatXD\n",
      "AutomaticFlowers\n",
      "Intrepid_Method_\n",
      "glorious_lechuga\n",
      "-RicFlair\n",
      "Johnnyamaz\n",
      "anaccountofrain\n",
      "BaguetteDelendaEst\n",
      "Vsaucer\n",
      "_Vorcaer_\n",
      "blunnyblunders\n",
      "kingstondnb\n",
      "PM_YOUR_HOT_BUTTHOLE\n",
      "joshypoo\n",
      "subgeniusbuttpirate\n",
      "TurboCapitalist\n",
      "Sanquinity\n",
      "Blinky39\n",
      "mrRandomGuy02\n",
      "OregonTripleBeam\n",
      "Brainkraker\n",
      "Golanthanatos\n",
      "astrobabe2\n",
      "graebot\n",
      "Dyingdaze89\n",
      "praefectus_praetorio\n",
      "ReddJudicata\n",
      "knows_knothing\n",
      "dataminer-x\n",
      "megatronchote\n",
      "bombstick\n",
      "TakeYouOnAJourney8\n",
      "joosth3\n",
      "ackillesBAC\n",
      "evogenome\n",
      "bloody_phlegm\n",
      "aMONAY69\n",
      "Billsolson\n",
      "blurplethenurple\n",
      "PressurePass\n",
      "Djmesh\n",
      "999baz\n",
      "Treydo1\n",
      "Forbiddentru\n",
      "Notnasiul\n",
      "NobleRayne\n",
      "ExpressStation\n",
      "tqb\n",
      "Reddit_Ghost2021\n",
      "ZiggyftOJ\n",
      "Skaindire\n",
      "Cryptoman_CRO\n",
      "MAROMODS\n",
      "YuppieKiYay\n",
      "MarkMoneyj27\n",
      "Gulrix\n",
      "itsastickup\n",
      "do_i_no_u\n",
      "stuckwithaweirdo\n",
      "NWSGreen\n",
      "SpiralCutTurnipWater\n",
      "snugglebunny822\n",
      "AhhGramoofabits\n",
      "BellaFace\n",
      "Wagamaga\n",
      "kaurib\n",
      "jglynnlc\n",
      "nithou\n",
      "qwerty12qwerty\n",
      "BeardedBears\n",
      "TheRiverStyx\n",
      "superRedditer\n",
      "sfzombie13\n",
      "Various_Judgment\n",
      "AM_Kylearan\n",
      "Meddel5\n",
      "cannarchista\n",
      "TX908\n",
      "jactheripper\n",
      "nostalgiapathy\n",
      "GrenadeAnaconda\n",
      "Aiku\n",
      "avogadros_number\n",
      "NormalTuesdayKnight\n",
      "blaskoa\n",
      "YourAuntie\n",
      "HarlanCulpepper\n",
      "gellenburg\n",
      "threeSOUL\n",
      "DarkJester89\n",
      "Torance39\n",
      "JBread0\n",
      "jerik22\n",
      "ClarkFable\n",
      "mikeman442\n",
      "mvogel0311\n",
      "cavemanfitz\n",
      "Ganjiek\n",
      "Garaleth\n",
      "Tuga_Lissabon\n",
      "jratreddit\n",
      "Marti1PH\n",
      "turtlesubie\n",
      "XtraLargeMarge\n",
      "hateiseasier\n",
      "ConservativeLiberalX\n",
      "Salesman89\n",
      "AutoModerator\n",
      "Insamity\n",
      "jazzcuzzii\n",
      "1rubyglass\n",
      "whocareswerefreaks\n",
      "rahduke\n",
      "Tlhingan\n",
      "Data-Hungry\n",
      "paulinsky\n",
      "frodolass0327\n",
      "Remote-Management-84\n",
      "Fillenintheblanks\n",
      "operator139\n",
      "TheGreenBehren\n",
      "BlackKnightLight\n",
      "AlbuterolHits\n",
      "sirfuzzitoes\n",
      "anonymousmiku\n",
      "TomArday\n",
      "Ok_Lifeguard_6508\n",
      "DeviceOpening4638\n",
      "whitehusky\n",
      "supagirl277\n",
      "nightmareuki\n",
      "thebelsnickle1991\n",
      "Gottanamegottanumber\n",
      "Slash1909\n",
      "I-seek-adventure\n",
      "ideas52\n",
      "Stunning-Hat5871\n",
      "OneWorldMouse\n",
      "TheStabbyBrit\n",
      "Roman_____Holiday\n",
      "SiliconeBuddha\n",
      "Bee_Rye85\n",
      "K1rkl4nd\n",
      "pl709\n",
      "ExmoColdDodger\n",
      "the--larch\n",
      "PanickyHermit\n",
      "bellasuperstring\n",
      "ArtisticCategory8792\n",
      "UnkindPotato\n",
      "WeAreLivinTheLife\n",
      "bustedbuddha\n",
      "gangler52\n",
      "Kraphtuos968\n",
      "Flonkers\n",
      "merchant_of_mirrors\n",
      "Sandisbad\n",
      "Tamazin_\n",
      "smurfyjenkins\n",
      "Psyese\n",
      "Majin_Vendetta\n",
      "ninja_natalia\n",
      "AllanfromWales1\n",
      "peanut_peanutbutter\n",
      "mathigh\n",
      "BBTB2\n",
      "Macrocosmic_Explorer\n",
      "Blasterbom\n",
      "ajeffri\n",
      "radiogeek\n",
      "RedPanda330i\n",
      "Srebrnalisica\n",
      "Vegetable_Ad6969\n",
      "clintCamp\n",
      "reddittmtr\n",
      "Electricpants\n",
      "nautikal\n",
      "DvrthKen\n",
      "log_sin\n",
      "Wants-NotNeeds\n",
      "kitreia\n",
      "urban_snowshoer\n",
      "HalforcFullLover\n",
      "tweb2\n",
      "tlw31415\n",
      "RaffiaWorkBase\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReasonablyBadass\n",
      "eric9495\n",
      "LONEGOAT13_\n",
      "alnueman1\n",
      "Philmeiweep\n",
      "Davo-80\n",
      "_bobby_tables_\n",
      "daemn42\n",
      "bindermichi\n",
      "Ok-File2825\n",
      "BeginningTower2486\n",
      "Alt_throwaway1020\n",
      "reddititty69\n",
      "Not_A_Bird11\n",
      "HammofGlob\n",
      "dodsbo\n",
      "siriously1234\n",
      "SamJackson01\n",
      "shinypennyonthefloor\n",
      "Rispy_Girl\n",
      "Arkeband\n",
      "Wolfram_Hebmuller\n",
      "vrosej10\n",
      "crostrom\n",
      "Stuart66\n",
      "TedTyro\n",
      "ArchitectNebulous\n",
      "Brynhilr\n",
      "ghaldos\n",
      "Johnmagee33\n",
      "leftoverpotatosalad\n",
      "Individual_Radio4523\n",
      "internetpointsbitch\n",
      "Artistic_Sound848\n",
      "ooofest\n",
      "narrative_device\n",
      "I_never_post_but\n",
      "PegasusFolley\n",
      "LynxDiscombobulated6\n",
      "issastrayngewerld\n",
      "TonLoc1281\n",
      "deadeye619\n",
      "Visual_Tumbleweed644\n",
      "Viddycentt\n",
      "StoicOptom\n",
      "Dessamba_Redux\n",
      "CurlSagan\n",
      "LordMooGoo\n",
      "errantgrammar\n",
      "skoltroll\n",
      "PistachioMarsupial\n",
      "socruisemebabe\n",
      "stupidhoes\n",
      "literallair\n",
      "CaseyBoogies\n",
      "kickassdonkey\n",
      "DarkEvilHedgehog\n",
      "Ragnar_Dragonfyre\n",
      "amesydragon\n",
      "virtuzoso\n",
      "totallylambert\n",
      "goosebattle\n",
      "ToxDocUSA\n",
      "Dd0G91\n",
      "canadianprotoss\n",
      "jorrylee\n",
      "Swoshu\n",
      "travelnman85\n",
      "jebrennan\n",
      "MediumProfessorX\n",
      "spoobydoo\n",
      "dvdmaven\n",
      "Lokiwastxtonly\n",
      "mymar101\n",
      "QuantumHope\n",
      "inbetween_inbetween\n",
      "jimboknows6916\n",
      "PretendCry2160\n",
      "unimpressive_balls\n",
      "wasBank\n",
      "Crystalpuck\n",
      "PumpkinSpicedPudding\n",
      "0x00ff0000\n",
      "E_PunnyMous\n",
      "EconomistMagazine\n",
      "cunningcaring\n",
      "Cmdr_Toucon\n",
      "Confident_Bridge9811\n",
      "Tofu_NumChucks\n",
      "roycearoni\n",
      "CronoDAS\n",
      "TiredOfYoSheeit\n",
      "My_High_Ideas\n",
      "sschocolate\n",
      "Sweep145\n",
      "Ballwhacker\n",
      "Comfortable_Drive_78\n",
      "Str8butboysrsexy\n",
      "Ferricplusthree\n",
      "fargmania\n",
      "harrison1454\n",
      "oxide-NL\n",
      "DoubleBatman\n",
      "asfgfjkydr2145623\n",
      "NRichYoSelf\n",
      "OldDale\n",
      "TerdSandwich\n",
      "mostitostedium\n",
      "dwaalman\n",
      "GottaGetMoon\n",
      "Tahh\n",
      "smokeout3000\n",
      "PlumpQuietSoup\n",
      "Jason_Batemans_Hair\n",
      "subiewoo89\n",
      "TequillaShotz\n",
      "PhaseVariance_0p33\n",
      "Bonobo555\n",
      "the_average_homeboy\n",
      "Q-ArtsMedia\n",
      "greedycow776\n",
      "Slatemanforlife\n",
      "helm\n",
      "ragnarok62\n",
      "SemanticTriangle\n",
      "tenderlylonertrot\n",
      "stivo\n",
      "joelex8472\n",
      "PA2SK\n",
      "bnzboy\n",
      "afraidofallthings\n",
      "danktle\n",
      "LongJohnSausage\n",
      "Roobubba\n",
      "JordanZr\n",
      "Snuffy1717\n",
      "MBeebeCIII\n",
      "fordprefect294\n",
      "givemethepassword\n",
      "Brokenbonesjunior\n",
      "KeyStoneLighter\n",
      "Bonfalk79\n",
      "cdreid\n",
      "TouchingHair\n",
      "barzbub\n",
      "Komacho\n",
      "Greatoutdoors1985\n",
      "ThisPlatformIsBad\n",
      "Astroniglio\n",
      "norse_dog\n",
      "nnomadic\n",
      "No-Loss9423\n",
      "tocksin\n",
      "elegantXsabotage\n",
      "bigthama\n",
      "Paradox_Dolphin\n",
      "Much_Difference\n",
      "md222\n",
      "XxNukeMutantxX\n",
      "ThioEther\n",
      "Candytuffnz\n",
      "nclh77\n",
      "MistWeaver80\n",
      "surfkw\n",
      "passinghere\n",
      "Difficult_Glove_6410\n",
      "Known-Ad9392\n",
      "greattsathoggua\n",
      "uberduger\n",
      "Stemms123\n",
      "TheBankTank\n",
      "Wonderful-Reward3828\n",
      "Trevorblackwell420\n",
      "tlucas\n",
      "Hung_Chi_Burbs\n",
      "Devinalh\n",
      "StarMasher\n",
      "juxtoppose\n",
      "david76\n",
      "Accurate-Horse1061\n",
      "kennykrunk\n",
      "tmsdave\n",
      "M134RotaryCannon\n",
      "charismatic_carcass\n",
      "Bovey\n",
      "LoboMagnum\n",
      "Makasuro\n",
      "logic_over_emoti0n\n",
      "Lee28104\n",
      "savagelife089\n",
      "dorisfrench\n",
      "Giblet_\n",
      "Aquapig\n",
      "junebugreggae\n",
      "smala017\n",
      "a_Ninja_b0y\n",
      "jenny_shiny_penny\n",
      "hdksjabsjs\n",
      "mr78rpm\n",
      "GhostalMedia\n",
      "Jane_doel\n",
      "annaflixion\n",
      "fastgtr14\n",
      "8ell0\n",
      "AliceB2021\n",
      "Smurfaccount1337\n",
      "------ No Posts ------\n",
      "------ No Comments ------\n",
      "Alklazaris\n",
      "ImmuneHack\n",
      "Robbotlove\n",
      "BibloDickins\n",
      "pbesmoove\n",
      "TimNickens\n",
      "silashoulder\n",
      "menickc\n",
      "Devilpig13\n",
      "LostMyKarmaElSegundo\n",
      "Rackminster\n",
      "edaum0726\n",
      "quinnsterr\n",
      "Juiceworld\n",
      "Persianboy7thst\n",
      "Amygdalump\n",
      "CarBombtheDestroyer\n",
      "DrSuperHappyFace\n",
      "mackhand\n",
      "NeThZOR\n",
      "Difficult-Diver4545\n",
      "WiIdCherryPepsi\n",
      "overmonk\n",
      "Fibonacci11235813\n",
      "shsc82\n",
      "ElectronGuru\n",
      "Sclera_Apoc\n",
      "vanyali\n",
      "thotherder\n",
      "Old7777\n",
      "Gueulemer\n",
      "BikerRay\n",
      "vBLADEv\n",
      "thermodynamicMD\n",
      "Manybadgers\n",
      "cranberrygoo\n",
      "Educational-Ad-5962\n",
      "Sentientdoing\n",
      "Rekstar369\n",
      "RandyDinglefart\n",
      "Bacon_Techie\n",
      "Goodbadugly16\n",
      "PottedFox\n",
      "marvlyn\n",
      "shutupdavid0010\n",
      "BodhiBill\n",
      "RoyalCSGO\n",
      "Fmatosqg\n",
      "BradLabreche\n",
      "echoAwooo\n",
      "zxcvbnmike15\n",
      "Cocohomlogy\n",
      "OracleDadOw\n",
      "The_camperdave\n",
      "TheRIPwagon\n",
      "SteeeveTheSteve\n",
      "The-Gino-101\n",
      "unstarvingartist\n",
      "2Woodyy\n",
      "D4rk50ul\n",
      "J-Bane\n",
      "manrealityisabitch\n",
      "DjTotherflow\n",
      "Brobi_Wan\n",
      "ChiknBreast\n",
      "JustKimNotKimberly\n",
      "frikkiefree2\n",
      "educated_giraffe\n",
      "SpookyDoomCrab42\n",
      "echo6golf\n",
      "The_alchemist667\n",
      "standardtrickyness1\n",
      "gitsgrl\n",
      "CAPTAIN_BL0WHARD\n",
      "Thtb\n",
      "DoomEmpires\n",
      "Maycke25\n",
      "thecolourofthisstone\n",
      "Fronesis\n",
      "Ragingoholic\n",
      "zephyreblk\n",
      "Stellarspace1234\n",
      "_andthereiwas\n",
      "ThreeEleven311311\n",
      "linkdude212\n",
      "hindermore\n",
      "Patbach\n",
      "itsYourLifeCoach\n",
      "MarcHerb\n",
      "ds0987654321\n",
      "g9icy\n",
      "ddarner\n",
      "Reimbirthed\n",
      "PikachuSaves\n",
      "mmceorange\n",
      "brokendreamz101\n",
      "monkey_sage\n",
      "obrieno\n",
      "7-billion-and-1\n",
      "Magic18\n",
      "Squadeep\n",
      "TheRoach\n",
      "ManagementPlane5283\n",
      "bdhubbard\n",
      "spunkyboy247365\n",
      "londonmenace\n",
      "Neo-Neo\n",
      "rxg\n",
      "Esc_ape_artist\n",
      "__________________99\n",
      "Ron_MF_Swanson\n",
      "Atiscomin\n",
      "Powerthrucontrol\n",
      "mihaicbnk\n",
      "Celebrindans\n",
      "Bravisimo\n",
      "StarDustLuna3D\n",
      "Flimsy_Outcome_5809\n"
     ]
    }
   ],
   "source": [
    "# 100 most recent posts and 100 most recent comments made by each user\n",
    "\n",
    "for user in unique_users:\n",
    "    \n",
    "    print(user)\n",
    "    \n",
    "    # Creating a list of lists with a single element containing strings that will serve as column names\n",
    "   \n",
    "    user_activity = [['subreddit', 'score', 'awards', 'comments']]\n",
    "    \n",
    "    # Posts made by User\n",
    "\n",
    "    headers = {\"Authorization\": f\"bearer {token}\", \"User-Agent\": f\"script:com.example.{app_name}:v1.0.0 (by u/{username})\"}\n",
    "    posts = requests.get(f\"https://oauth.reddit.com/user/{user}/submitted?limit=100\", headers=headers)\n",
    "    \n",
    "    # User may not have made any posts\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # User has made at least one post\n",
    "    \n",
    "        for x in posts.json()['data']['children']:\n",
    "\n",
    "            \n",
    "            p = []\n",
    "            # The subreddit the post was published in\n",
    "            p.append(x['data']['subreddit'])\n",
    "            # The total score the post has received thus far \n",
    "            p.append(x['data']['score'])\n",
    "            # The total number of awards the post has received thus far\n",
    "            p.append(x['data']['total_awards_received'])\n",
    "            # The number of comments the post has received thus far\n",
    "            p.append(x['data']['num_comments'])\n",
    "\n",
    "            user_activity.append(p)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        # User has made no posts \n",
    "        \n",
    "        pass\n",
    "        \n",
    "    # Comments made by User\n",
    "\n",
    "    headers = {\"Authorization\": f\"bearer {token}\", \"User-Agent\": f\"script:com.example.{app_name}:v1.0.0 (by u/{username})\"}\n",
    "    comments = requests.get(f\"https://oauth.reddit.com/user/{user}/comments?limit=100\", headers=headers)\n",
    "\n",
    "    # User may not have made any comments\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # User has made at least one comment\n",
    "        \n",
    "        for x in comments.json()['data']['children']:\n",
    "\n",
    "            c = []\n",
    "            # The subreddit the comment was published in\n",
    "            c.append(x['data']['subreddit'])\n",
    "            # The total score the comment has received thus far \n",
    "            c.append(x['data']['score'])\n",
    "            # The total number of awards the comment has received thus far\n",
    "            c.append(x['data']['total_awards_received'])\n",
    "            # Inserting NaN as there is no data regarding number of comments received on a comment \n",
    "            c.append(np.nan)\n",
    "\n",
    "            user_activity.append(c)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        # User has made no comments \n",
    "        \n",
    "        pass\n",
    "        \n",
    "    # Establishing a key : value pair of the format username : list of lists\n",
    "    \n",
    "    subreddits[user] = user_activity\n",
    "    \n",
    "# If a user has no posts and no comments, it is likely because their account has been deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf9e2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a empty dictionary\n",
    "\n",
    "random_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11157595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting list of lists into pandas DataFrame for each user\n",
    "\n",
    "for user in subreddits.keys():\n",
    "    \n",
    "    random_dict[user] = pd.DataFrame(subreddits[user][1:], columns=subreddits[user][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37f276ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b787ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing users who have made no posts or comments (ie accounts have been deleted)\n",
    "\n",
    "to_del = []\n",
    "\n",
    "for user in random_dict.keys():\n",
    "    \n",
    "    if len(random_dict[user]) == 0:\n",
    "        \n",
    "        to_del.append(user)\n",
    "        \n",
    "for user in to_del:\n",
    "    \n",
    "    del random_dict[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36b2dc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1814f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing users sourced from other subreddits ('aww', 'science', 'food') who have interacted with 'wallstreetbets'\n",
    "\n",
    "if seed_subreddit != 'wallstreetbets':\n",
    "\n",
    "    to_del = []\n",
    "\n",
    "    for user in random_dict.keys():\n",
    "\n",
    "        if 'wallstreetbets' in random_dict[user].subreddit:\n",
    "\n",
    "            to_del.append(user)\n",
    "\n",
    "    for user in to_del:\n",
    "\n",
    "        del random_dict[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f29ba7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9afa0",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "See example walkthrough with single user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c6c98c",
   "metadata": {},
   "source": [
    "### Scoring Methodology\n",
    "\n",
    "Number of posts/comments made on subreddit\n",
    "\n",
    "x ( 1 + (score on subreddit / sum of all scores received) )\n",
    "\n",
    "x ( 1 + (awards on subreddit / sum of all awards received) ) \n",
    "\n",
    "x ( 1 + (comments received on subreddit / sum of all comments received) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d097f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an empty dictionary\n",
    "\n",
    "new_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e7b46b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mr/grw5wh_16jj7l0dz_n0t58tw0000gn/T/ipykernel_35030/2884540799.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.comments[i] = 0\n",
      "/var/folders/mr/grw5wh_16jj7l0dz_n0t58tw0000gn/T/ipykernel_35030/2884540799.py:66: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  1 + (x.awards[i] / x.awards.sum())]\n",
      "/var/folders/mr/grw5wh_16jj7l0dz_n0t58tw0000gn/T/ipykernel_35030/2884540799.py:41: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  1 + (x.awards[i] / x.awards.sum())]\n"
     ]
    }
   ],
   "source": [
    "for user in random_dict.keys():\n",
    "    \n",
    "    # Creating a list of lists with a single element containing strings that will serve as column names\n",
    "    \n",
    "    pss = [['subreddit', 'interactions', 'score', 'awards', 'comments']]\n",
    "\n",
    "    x = random_dict[user]\n",
    "\n",
    "    for sub in x.subreddit.unique():\n",
    "        \n",
    "        if sub != 'wallstreetbets':\n",
    "\n",
    "            ps = []\n",
    "            # The name of the subreddit\n",
    "            ps.append(sub)\n",
    "            # The number of interactions with that subreddit\n",
    "            ps.append(x.subreddit.value_counts()[sub])\n",
    "            # The mean score received across all interactions with that subreddit\n",
    "            ps.append(x[x.subreddit == sub].score.mean())\n",
    "            # The mean number of awards received across all interactions with that subreddit\n",
    "            ps.append(x[x.subreddit == sub].awards.mean())\n",
    "            # The mean number of comments received across all interactions with that subreddit\n",
    "            ps.append(x[x.subreddit == sub].comments.mean())\n",
    "\n",
    "            pss.append(ps)\n",
    "\n",
    "    # Converting the list of lists into a pandas dataframe\n",
    "    \n",
    "    x = pd.DataFrame(pss[1:], columns=pss[0])\n",
    "\n",
    "    # Defining an empty list\n",
    "    \n",
    "    a = []\n",
    "\n",
    "    for i in x.index:\n",
    "        \n",
    "        # If a given row/subreddit does not contain a NaN value in the 'comments' column\n",
    "        # the user has published at least one post in that subreddit\n",
    "\n",
    "        if x.comments.isna()[i] == False: # Posts \n",
    "\n",
    "            # Using the methodology defined above, a users score/value for a given subreddit will be calculated\n",
    "            \n",
    "            # We will be using normalised values so we must account for cases where a user has never received \n",
    "            # any awards or comments as this would result in division by 0\n",
    "            \n",
    "            if x.awards.sum() != 0 and x.comments.sum() != 0 :\n",
    "\n",
    "                # Creating a list containing the elements that will be used to calculate a single value\n",
    "\n",
    "                aa = [x.interactions[i], 1 + (x.score[i] / x.score.sum()), 1 + (x.awards[i] / x.awards.sum()), \n",
    "                      1 + (x.comments[i] / x.comments.sum())]\n",
    "\n",
    "            elif x.comments.sum() == 0:\n",
    "\n",
    "                # Creating a list containing the elements that will be used to calculate a single value\n",
    "                \n",
    "                aa = [x.interactions[i], 1 + (x.score[i] / x.score.sum()), \n",
    "                      1 + (x.awards[i] / x.awards.sum())]\n",
    "\n",
    "            elif x.awards.sum() == 0:\n",
    "\n",
    "                # Creating a list containing the elements that will be used to calculate a single value\n",
    "\n",
    "                aa = [x.interactions[i], 1 + (x.score[i] / x.score.sum()), \n",
    "                     1 + (x.comments[i] / x.comments.sum())]\n",
    "\n",
    "            # Finally calculating the single score/value by taking the product of the elements in the list\n",
    "                \n",
    "            aaa = np.prod(aa)\n",
    "\n",
    "\n",
    "        # If a given row/subreddit contains a NaN value in the 'comments' column\n",
    "        # the user has not published any posts in that subreddit\n",
    "            \n",
    "        else: # Comments\n",
    "\n",
    "            x.comments[i] = 0\n",
    "\n",
    "            if x.awards.sum() != 0 and x.comments.sum() != 0 :\n",
    "                \n",
    "                # Creating a list containing the elements that will be used to calculate a single value\n",
    "\n",
    "                aa = [x.interactions[i], 1 + (x.score[i] / x.score.sum()), 1 + (x.awards[i] / x.awards.sum()), \n",
    "                     1 + (x.comments[i] / x.comments.sum())]\n",
    "\n",
    "            elif x.comments.sum() == 0:\n",
    "\n",
    "                # Creating a list containing the elements that will be used to calculate a single value\n",
    "\n",
    "                aa = [x.interactions[i], 1 + (x.score[i] / x.score.sum()), \n",
    "                      1 + (x.awards[i] / x.awards.sum())]\n",
    "\n",
    "            elif x.awards.sum() == 0:\n",
    "\n",
    "                # Creating a list containing the elements that will be used to calculate a single value\n",
    "                \n",
    "                aa = [x.interactions[i], 1 + (x.score[i] / x.score.sum()), \n",
    "                     1 + (x.comments[i] / x.comments.sum())]\n",
    "                \n",
    "            # Finally calculating the single score/value by taking the product of the elements in the list\n",
    "            \n",
    "            # As the user has never posted on this subreddit but only commented, the final value is half weighted\n",
    "\n",
    "            aaa = np.prod(aa) / 2\n",
    "\n",
    "\n",
    "        # Appending the final value to the empty list defined above\n",
    "\n",
    "        a.append(aaa)\n",
    "\n",
    "    # Inserting final value into a new column in the dataframe \n",
    "\n",
    "    x['value'] = a\n",
    "    \n",
    "    # Reducing the dataframe to just the columns of interest\n",
    "    x = x[['subreddit', 'value']]\n",
    "    \n",
    "    # Setting the subreddit names as the dataframe index\n",
    "    x.reset_index(inplace=True, drop=True)\n",
    "    x.set_index('subreddit', inplace=True)\n",
    "    x.index.name = None\n",
    "    \n",
    "    # Redefining the 'value' column name as the user's username\n",
    "    x.columns = [user]\n",
    "    \n",
    "    # Transposing the dataframe from a single column into a single row\n",
    "    x = x.T\n",
    "    \n",
    "    # Assigning target classes\n",
    "    \n",
    "    if seed_subreddit == 'wallstreetbets':\n",
    "        \n",
    "        x['Target'] = 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        x['Target'] = 0\n",
    "\n",
    "        \n",
    "    new_dict[user] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "445a0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all subreddits users have interacted with\n",
    "\n",
    "subs_list = []\n",
    "\n",
    "for x in new_dict.keys():\n",
    "    \n",
    "    for y in new_dict[x].columns:\n",
    "        \n",
    "        subs_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bff44a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38329, 9396)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of unique subreddits\n",
    "\n",
    "len(subs_list), len(set(subs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1ca8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a list of unique list of subreddits users have interacted with (+ 'Target')\n",
    "\n",
    "subs_set = list(set(subs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ba94cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty (NaN) DataFrame with users as rows and subreddits + Target as columns\n",
    "\n",
    "df = pd.DataFrame(np.nan, columns=subs_set, index=new_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dba2f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating the empty DataFrame with user/subreddit values\n",
    "\n",
    "for x in new_dict.keys():\n",
    "    \n",
    "    for y in new_dict[x].columns:\n",
    "        \n",
    "        df.loc[x, y] = new_dict[x].loc[x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37e62a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862, 9395)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3dc41553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for empty columns\n",
    "\n",
    "len(df.isna().sum()[df.isna().sum() == df.shape[0]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2ff5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing empty columns\n",
    "\n",
    "drop_cols = list(df.isna().sum()[df.isna().sum() == df.shape[0]].index)\n",
    "df.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11710f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862, 8546)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4499df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure 'wallstreetbets' is not in the DataFrame\n",
    "\n",
    "'wallstreetbets' in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d596e30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure 'Target' is in the DataFrame\n",
    "\n",
    "'Target' in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27ff98c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RedditDayOf</th>\n",
       "      <th>InsideTheSoulStone</th>\n",
       "      <th>WatchPeopleDieInside</th>\n",
       "      <th>xcmtb</th>\n",
       "      <th>Irony</th>\n",
       "      <th>bristol</th>\n",
       "      <th>nocontext</th>\n",
       "      <th>u_EmbarrassedHelp</th>\n",
       "      <th>AskDoctorSmeeee</th>\n",
       "      <th>Dodocodes</th>\n",
       "      <th>...</th>\n",
       "      <th>ryzen</th>\n",
       "      <th>BPDlovedones</th>\n",
       "      <th>dirtypenpals</th>\n",
       "      <th>crtgaming</th>\n",
       "      <th>minipainting</th>\n",
       "      <th>EverythingScience</th>\n",
       "      <th>CatsISUOTTATFO</th>\n",
       "      <th>EulaMains</th>\n",
       "      <th>u_ExmoColdDodger</th>\n",
       "      <th>NarcoticsAnonymous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SmokeyBare</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine_yearning</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LetReasonRing</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TomorrowWeKillToday</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rupertfitz</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.504052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8546 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RedditDayOf  InsideTheSoulStone  WatchPeopleDieInside  \\\n",
       "SmokeyBare                   NaN                 NaN                   NaN   \n",
       "machine_yearning             NaN                 NaN                   NaN   \n",
       "LetReasonRing                NaN                 NaN                   NaN   \n",
       "TomorrowWeKillToday          NaN                 NaN                   NaN   \n",
       "Rupertfitz                   NaN                 NaN                   NaN   \n",
       "\n",
       "                     xcmtb  Irony  bristol  nocontext  u_EmbarrassedHelp  \\\n",
       "SmokeyBare             NaN    NaN      NaN        NaN                NaN   \n",
       "machine_yearning       NaN    NaN      NaN        NaN                NaN   \n",
       "LetReasonRing          NaN    NaN      NaN        NaN                NaN   \n",
       "TomorrowWeKillToday    NaN    NaN      NaN        NaN                NaN   \n",
       "Rupertfitz             NaN    NaN      NaN        NaN                NaN   \n",
       "\n",
       "                     AskDoctorSmeeee  Dodocodes  ...  ryzen  BPDlovedones  \\\n",
       "SmokeyBare                       NaN        NaN  ...    NaN           NaN   \n",
       "machine_yearning                 NaN        NaN  ...    NaN           NaN   \n",
       "LetReasonRing                    NaN        NaN  ...    NaN           NaN   \n",
       "TomorrowWeKillToday              NaN        NaN  ...    NaN           NaN   \n",
       "Rupertfitz                       NaN        NaN  ...    NaN           NaN   \n",
       "\n",
       "                     dirtypenpals  crtgaming  minipainting  EverythingScience  \\\n",
       "SmokeyBare                    NaN        NaN           NaN                NaN   \n",
       "machine_yearning              NaN        NaN           NaN                NaN   \n",
       "LetReasonRing                 NaN        NaN           NaN                NaN   \n",
       "TomorrowWeKillToday           NaN        NaN           NaN                NaN   \n",
       "Rupertfitz                    NaN        NaN           NaN           3.504052   \n",
       "\n",
       "                     CatsISUOTTATFO  EulaMains  u_ExmoColdDodger  \\\n",
       "SmokeyBare                      NaN        NaN               NaN   \n",
       "machine_yearning                NaN        NaN               NaN   \n",
       "LetReasonRing                   NaN        NaN               NaN   \n",
       "TomorrowWeKillToday             NaN        NaN               NaN   \n",
       "Rupertfitz                      NaN        NaN               NaN   \n",
       "\n",
       "                     NarcoticsAnonymous  \n",
       "SmokeyBare                          NaN  \n",
       "machine_yearning                    NaN  \n",
       "LetReasonRing                       NaN  \n",
       "TomorrowWeKillToday                 NaN  \n",
       "Rupertfitz                          NaN  \n",
       "\n",
       "[5 rows x 8546 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the populated DataFrame\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea136d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4653daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving DataFrame to CSV\n",
    "\n",
    "if seed_subreddit = 'wallstreetbets':\n",
    "    \n",
    "    df.to_csv(f'target_1.csv')\n",
    "    \n",
    "else:\n",
    "\n",
    "    df.to_csv(f'target_0_{seed_subreddit}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7200939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e60925c",
   "metadata": {},
   "source": [
    "# Concatinating seperate DataFrames into complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae9729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6684bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSVs into DataFrames\n",
    "\n",
    "wsb = pd.read_csv('target_1.csv')\n",
    "aww = pd.read_csv('target_0_aww.csv')\n",
    "science = pd.read_csv('target_0_science.csv')\n",
    "food = pd.read_csv('target_0_food.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting users as index\n",
    "\n",
    "wsb.set_index('Unnamed: 0', inplace=True)\n",
    "wsb.index.name = None\n",
    "\n",
    "aww.set_index('Unnamed: 0', inplace=True)\n",
    "aww.index.name = None\n",
    "\n",
    "science.set_index('Unnamed: 0', inplace=True)\n",
    "science.index.name = None\n",
    "\n",
    "food.set_index('Unnamed: 0', inplace=True)\n",
    "food.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaaeece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating seperate DataFrames into complete dataset \n",
    "\n",
    "df = pd.concat([wsb, aww, science, food])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b01c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate users\n",
    "# Would have used .drop_duplicates(), however it is possible that a user has had additional interactions since \n",
    "\n",
    "drop_rows = df.index.value_counts()[df.index.value_counts() > 1].index\n",
    "df2.drop(index=drop_rows, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing empty columns\n",
    "\n",
    "drop_cols = list(df.isna().sum()[df.isna().sum() == df.shape[0]].index)\n",
    "df.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking out DataFrame\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25ac8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e709b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving complete dataset to CSV\n",
    "\n",
    "df.to_csv('reddit_class_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf84056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab7da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
